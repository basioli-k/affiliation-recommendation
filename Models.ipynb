{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.sparse import csc_matrix, bmat, load_npz\n",
    "from scipy.sparse.linalg import svds\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = load_npz(\"data/s.npz\")\n",
    "a_train = load_npz(\"data/a_train.npz\")\n",
    "a_test = load_npz(\"data/a_test.npz\")\n",
    "a_val = load_npz(\"data/a_val.npz\")\n",
    "n_groups = a_train.shape[1]\n",
    "n_users = s.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_data(alpha, s, a_train, a_val):\n",
    "    c_train = bmat([[alpha*s, a_train], [a_train.transpose(), None]])\n",
    "    c_val = bmat([[alpha*s, a_val], [a_val.transpose(), None]])\n",
    "    #c_test = bmat([[alpha*s, a_test], [a_test.transpose(), None]])    \n",
    "    return c_train, c_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"vrati listu (za k = 1:n) precisiona i recalla na testu za jednog usera\"\n",
    "def evaluate_latent_factor_user(i, n, u, sig, vt, c_train, c_val, n_groups):\n",
    "    \"i = user za kojeg generiramo recommendatione\"\n",
    "    score = (u[i,:]@np.diag(sig)@vt)[-n_groups:]\n",
    "    true_labels = c_val.getrow(i).toarray().flatten()[-n_groups:]\n",
    "    train_labels = c_train.getrow(i).toarray().flatten()[-n_groups:]\n",
    "    score = np.multiply(score, np.logical_not(train_labels))\n",
    "    score_index = np.flip(np.argsort(score))\n",
    "    positives = np.sum(true_labels)\n",
    "    negatives = n_groups - positives\n",
    "    user_i_stats = []\n",
    "    for predictions in range(1, n+1):\n",
    "        recommendations = score_index[:predictions]\n",
    "        true_positives = np.sum(true_labels[recommendations] == 1)\n",
    "        true_negatives = negatives - (predictions - true_positives)\n",
    "        precision = true_positives/predictions\n",
    "        sensitivity = true_positives/positives if positives != 0 else 1\n",
    "        specificity = true_negatives/negatives\n",
    "        user_i_stats.append((precision, sensitivity, specificity))\n",
    "    return user_i_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_latent_factors(u, sig, vt, c_train, c_val, n_users, n_groups):\n",
    "    stats = []\n",
    "    for i in tqdm(range(n_users)):\n",
    "        stats.append(evaluate_latent_factor_user(i, 100, u, sig, vt, c_train, c_val, n_groups))\n",
    "    \"stats mi je lista duljine broj usera, svaki element je lista duljine n koja sadrzi tupleove oblika (pr, se, sp)\"\n",
    "    pr_se_sp = []\n",
    "    \"pr_se_sp ce biti lista tupleova duljine n, tuple je oblika (mean_pr, mean_se, mean_sp) gdje je prosjek uzet po userima\"\n",
    "    for n in zip(*stats):\n",
    "        pr_se_sp.append((np.mean([i for i,j,k in n]), np.mean([j for i,j,k in n]), np.mean([k for i,j,k in n])))\n",
    "    \"pss ce biti numpy array dimenzija n x 3, svaki stupac odgovara jednom od (pr, se, sp)\"\n",
    "    pss = np.array(pr_se_sp)\n",
    "    return pss[:,0], pss[:,1], pss[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(precision, sensitivity, specificity):\n",
    "    x=[(1-spec) for spec in specificity]\n",
    "    area = np.trapz(y=sensitivity, x=x)\n",
    "    return abs(area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_factors_model(alpha, svd_rank, s, a_train, a_val, n_users, n_groups):\n",
    "    c_train, c_val = prepare_train_data(alpha, s, a_train, a_val)\n",
    "    c_train = c_train.astype(np.float64)\n",
    "    c_val = c_val.astype(np.float64)\n",
    "    u, sig, vt = svds(c_train, k = svd_rank)\n",
    "    precision, sensitivity, specificity = evaluate_latent_factors(u, sig, vt, c_train, c_val, n_users, n_groups)\n",
    "    score = get_score(precision, sensitivity, specificity)\n",
    "    return {\"alpha\" : alpha, \"svd_rank\" : svd_rank, \"score\" : score, \"precision\" : precision, \"sensitivity\" : sensitivity, \"specificity\" : specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_latent_factor_model(alphas, svd_ranks, s, a_train, a_val, n_users, n_groups):\n",
    "    validation_scores = []\n",
    "    for alpha in alphas:\n",
    "        for svd_rank in svd_ranks:\n",
    "            validation_scores.append(latent_factors_model(alpha, svd_rank, s, a_train, a_val, n_users, n_groups))\n",
    "    return validation_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [3]\n",
    "svd_ranks = [10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:47<00:00, 93.19it/s]\n"
     ]
    }
   ],
   "source": [
    "validation_scores = validate_latent_factor_model(alphas, svd_ranks, s, a_train, a_val, n_users, n_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'alpha': 3,\n",
       "  'svd_rank': 10,\n",
       "  'score': 0.28565990285781884,\n",
       "  'precision': array([0.0557    , 0.0448    , 0.0385    , 0.03515   , 0.03176   ,\n",
       "         0.02913333, 0.02717143, 0.0252625 , 0.02362222, 0.02259   ,\n",
       "         0.02165455, 0.02071667, 0.01977692, 0.01897857, 0.01825333,\n",
       "         0.0176125 , 0.01705294, 0.01647778, 0.01598947, 0.01553   ,\n",
       "         0.01521429, 0.01486364, 0.0145087 , 0.014225  , 0.013868  ,\n",
       "         0.01362308, 0.01332222, 0.01304286, 0.01273448, 0.01247667,\n",
       "         0.01220323, 0.01199375, 0.01176667, 0.01160588, 0.01142   ,\n",
       "         0.01121111, 0.01103243, 0.01084737, 0.01066154, 0.01052   ,\n",
       "         0.01034634, 0.01016429, 0.01001395, 0.00986591, 0.00973333,\n",
       "         0.00957391, 0.00942979, 0.00931667, 0.00920612, 0.00907   ,\n",
       "         0.00896471, 0.00884808, 0.00874717, 0.00863148, 0.00851273,\n",
       "         0.00841964, 0.00832105, 0.00822759, 0.00812881, 0.00805333,\n",
       "         0.00796066, 0.00787742, 0.00778571, 0.00770781, 0.00761846,\n",
       "         0.00757121, 0.00748507, 0.00741324, 0.00733188, 0.00726143,\n",
       "         0.00719296, 0.00713611, 0.00707808, 0.00702297, 0.00696533,\n",
       "         0.00691184, 0.00685844, 0.00680641, 0.00675443, 0.00669375,\n",
       "         0.00664074, 0.00658902, 0.00652892, 0.006475  , 0.00643176,\n",
       "         0.00637558, 0.00632299, 0.00627727, 0.00623146, 0.00618889,\n",
       "         0.00614615, 0.00610217, 0.00606129, 0.00601596, 0.00597263,\n",
       "         0.005925  , 0.00588041, 0.00584286, 0.00581616, 0.005773  ]),\n",
       "  'sensitivity': array([0.03335457, 0.05255132, 0.06522206, 0.07826836, 0.08769004,\n",
       "         0.09615126, 0.10392637, 0.10945934, 0.11482787, 0.12091924,\n",
       "         0.1274177 , 0.13146318, 0.13553637, 0.13951466, 0.14314021,\n",
       "         0.14675207, 0.15102935, 0.15433355, 0.15797962, 0.1613604 ,\n",
       "         0.16531158, 0.16902548, 0.17216328, 0.17607519, 0.17817247,\n",
       "         0.1816532 , 0.18388049, 0.18716755, 0.18908873, 0.19186889,\n",
       "         0.19381959, 0.19627638, 0.19848797, 0.20131188, 0.20353674,\n",
       "         0.20535388, 0.20769667, 0.20935964, 0.21112913, 0.21321703,\n",
       "         0.21494752, 0.21645331, 0.21822   , 0.21985976, 0.22150528,\n",
       "         0.22291214, 0.22426674, 0.22592316, 0.2280347 , 0.22915419,\n",
       "         0.23125274, 0.23259991, 0.23404224, 0.23488151, 0.23576308,\n",
       "         0.23740497, 0.23873602, 0.24015236, 0.24087982, 0.24226184,\n",
       "         0.2430224 , 0.24426247, 0.24495518, 0.24628131, 0.24713913,\n",
       "         0.24918549, 0.2501416 , 0.25115551, 0.25213769, 0.2532376 ,\n",
       "         0.25454426, 0.25597122, 0.25750734, 0.2590828 , 0.26018761,\n",
       "         0.26150392, 0.26276447, 0.26396116, 0.26524084, 0.26612657,\n",
       "         0.2671893 , 0.26853018, 0.2697726 , 0.27058198, 0.2719236 ,\n",
       "         0.27256682, 0.27334359, 0.2742    , 0.27534365, 0.27657536,\n",
       "         0.27753109, 0.27851347, 0.27953276, 0.28049156, 0.28122112,\n",
       "         0.28171317, 0.28230825, 0.28343064, 0.28480042, 0.2856599 ]),\n",
       "  'specificity': array([0.99994486, 0.99988846, 0.99983158, 0.99977466, 0.99971733,\n",
       "         0.99965988, 0.99960239, 0.9995447 , 0.99948692, 0.99942931,\n",
       "         0.99937164, 0.99931386, 0.99925597, 0.99919809, 0.99914017,\n",
       "         0.99908225, 0.99902434, 0.99896634, 0.99890837, 0.99885038,\n",
       "         0.99879251, 0.99873456, 0.99867657, 0.99861863, 0.99856055,\n",
       "         0.9985026 , 0.99844454, 0.99838647, 0.99832832, 0.99827022,\n",
       "         0.99821207, 0.998154  , 0.99809588, 0.99803786, 0.99797977,\n",
       "         0.99792161, 0.99786349, 0.99780534, 0.99774716, 0.99768906,\n",
       "         0.99763087, 0.99757264, 0.99751447, 0.99745629, 0.99739813,\n",
       "         0.99733988, 0.99728166, 0.9972235 , 0.99716534, 0.99710709,\n",
       "         0.99704892, 0.9969907 , 0.99693252, 0.99687428, 0.99681601,\n",
       "         0.99675782, 0.9966996 , 0.99664138, 0.99658313, 0.99652495,\n",
       "         0.9964667 , 0.99640848, 0.99635021, 0.99629199, 0.99623371,\n",
       "         0.99617559, 0.99611731, 0.99605907, 0.99600079, 0.99594254,\n",
       "         0.99588429, 0.99582609, 0.99576787, 0.99570965, 0.99565142,\n",
       "         0.99559321, 0.99553498, 0.99547676, 0.99541853, 0.99536025,\n",
       "         0.995302  , 0.99524376, 0.99518546, 0.99512719, 0.99506897,\n",
       "         0.99501067, 0.99495239, 0.99489414, 0.99483588, 0.99477763,\n",
       "         0.99471938, 0.99466111, 0.99460286, 0.99454457, 0.9944863 ,\n",
       "         0.99442799, 0.9943697 , 0.99431144, 0.99425324, 0.99419494])}]"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Katz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def katz(t, beta, k):\n",
    "    katz = beta*t\n",
    "    a = beta*t\n",
    "    for i in range(k-1):\n",
    "        a = beta*a@t\n",
    "        katz = katz + a\n",
    "    return katz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def katz_2(t, beta, k):\n",
    "    t = t.astype(np.float64)\n",
    "    u, s, vt = svds(t, k=3)\n",
    "    s = np.diag(s)\n",
    "    \n",
    "    vtu = vt@u\n",
    "    svtu = s@vtu\n",
    "    \n",
    "    katz = beta*s\n",
    "    #a = beta*svtu\n",
    "    small_matrix = beta * s @ vtu\n",
    "    for i in range(k-1):\n",
    "        small_matrix = beta * small_matrix @ s\n",
    "        katz = katz + small_matrix\n",
    "        small_matrix = small_matrix @ vtu\n",
    "    katz = u @ katz @ vt\n",
    "    return katz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
