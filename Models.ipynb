{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.sparse import csc_matrix, bmat, load_npz, csr_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import implicit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = load_npz(\"data/yt_s.npz\")\n",
    "a_train = load_npz(\"data/yt_a_train.npz\")\n",
    "a_test = load_npz(\"data/yt_a_test.npz\")\n",
    "a_val = load_npz(\"data/yt_a_val.npz\")\n",
    "n_groups = a_train.shape[1]\n",
    "n_users = s.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_data(alpha, s, a_train, a_val):\n",
    "    c_train = bmat([[alpha*s, a_train], [a_train.transpose(), None]])\n",
    "    c_val = bmat([[alpha*s, a_val], [a_val.transpose(), None]])\n",
    "    #c_test = bmat([[alpha*s, a_test], [a_test.transpose(), None]])    \n",
    "    return c_train.astype(np.float64), c_val.astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_get_recs(i, model, train_labels, n_groups):\n",
    "        u, sig, vt = model\n",
    "        score = (u[i,:]@np.diag(sig)@vt)[-n_groups:]\n",
    "        score = np.multiply(score, np.logical_not(train_labels))\n",
    "        score_index = np.flip(np.argsort(score))\n",
    "        return score_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"vrati listu (za k = 1:n) precisiona i recalla na testu za jednog usera\"\n",
    "def evaluate_model_user(i, n, model, c_train, c_val, n_groups, model_type):\n",
    "    \"i = user za kojeg generiramo recommendatione\"\n",
    "    true_labels = c_val.getrow(i).toarray().flatten()[-n_groups:]\n",
    "    train_labels = c_train.getrow(i).toarray().flatten()[-n_groups:]\n",
    "    \n",
    "    \"tu se dodaju novi modeli\"\n",
    "    if model_type == \"SVD\":\n",
    "        score_index = svd_get_recs(i, model, train_labels, n_groups)\n",
    "    if model_type == \"ALS\":\n",
    "        score_index = als_get_recs(i, n, model, c_train, n_groups)\n",
    "        \n",
    "    positives = np.sum(true_labels)\n",
    "    negatives = n_groups - positives\n",
    "    user_i_stats = []\n",
    "    for predictions in range(1, n+1):\n",
    "        recommendations = score_index[:predictions]\n",
    "        true_positives = np.sum(true_labels[recommendations] == 1)\n",
    "        true_negatives = negatives - (predictions - true_positives)\n",
    "        precision = true_positives/predictions\n",
    "        sensitivity = true_positives/positives if positives != 0 else 1\n",
    "        specificity = true_negatives/negatives\n",
    "        user_i_stats.append((precision, sensitivity, specificity))\n",
    "    return user_i_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, c_train, c_val, n_users, n_groups, model_type):\n",
    "    stats = []\n",
    "    for i in tqdm(range(n_users)):\n",
    "            if np.sum(c_val.getrow(i).toarray().flatten()[-n_groups:]) != 0:\n",
    "                stats.append(evaluate_model_user(i, 50, model, c_train, c_val, n_groups, model_type))\n",
    "    \"stats mi je lista duljine broj usera, svaki element je lista duljine n koja sadrzi tupleove oblika (pr, se, sp)\"\n",
    "    pr_se_sp = []\n",
    "    \"pr_se_sp ce biti lista tupleova duljine n, tuple je oblika (mean_pr, mean_se, mean_sp) gdje je prosjek uzet po userima\"\n",
    "    for n in zip(*stats):\n",
    "        pr_se_sp.append((np.mean([i for i,j,k in n]), np.mean([j for i,j,k in n]), np.mean([k for i,j,k in n])))\n",
    "    \"pss ce biti numpy array dimenzija n x 3, svaki stupac odgovara jednom od (pr, se, sp)\"\n",
    "    pss = np.array(pr_se_sp)\n",
    "    return pss[:,0], pss[:,1], pss[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(precision, sensitivity, specificity):\n",
    "    x=[(1-spec) for spec in specificity]\n",
    "    area = np.trapz(y=sensitivity, x=x)\n",
    "    return abs(area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_model(alpha, svd_rank, s, a_train, a_val, n_users, n_groups):\n",
    "    c_train, c_val = prepare_train_data(alpha, s, a_train, a_val)\n",
    "    model = svds(c_train, k = svd_rank)\n",
    "    precision, sensitivity, specificity = evaluate_model(model, c_train, c_val, n_users, n_groups, model_type = \"SVD\")\n",
    "    score = get_score(precision, sensitivity, specificity)\n",
    "    return {\"alpha\" : alpha, \"svd_rank\" : svd_rank, \"score\" : score, \"precision\" : precision, \"sensitivity\" : sensitivity, \"specificity\" : specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_svd_model(alphas, svd_ranks, s, a_train, a_val, n_users, n_groups):\n",
    "    validation_scores = []\n",
    "    for alpha in alphas:\n",
    "        for svd_rank in svd_ranks:\n",
    "            validation_scores.append(svd_model(alpha, svd_rank, s, a_train, a_val, n_users, n_groups))\n",
    "    return validation_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [3]\n",
    "svd_ranks = [10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_scores_svd = validate_svd_model(alphas, svd_ranks, s, a_train, a_val, n_users, n_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_scores_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(1 - validation_scores_svd[0][\"specificity\"], validation_scores_svd[0][\"sensitivity\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUACIJA GENERALNO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"treba u evaluate_model_user za svaki model dodati granu u if-u u funkciji evaluate_model_user u kojoj se napravi score_index\"\n",
    "\"score_index je lista/np.array koji sadr≈æi indekse grupa sortirane po scoreu koji model daje, dakle sortirana lista grupa za recommendat\"\n",
    "\"ideja je da se dotad sve sto ti treba za evaluirati model prenosi u varijabli model, a onda unutar tog ifa se pozove neka funkcija koja evaluira\"\n",
    "\"za validaciju i kreiranje modela predlazem da se rade posebne funkcije za svaki jer nije bas zgodno napravit generalno, mogu biti po uzoru na ove\"\n",
    "precision, sensitivity, specificity = evaluate_model(model, c_train, c_val, n_users, n_groups, model_type = \"SVD\")\n",
    "score = get_score(precision, sensitivity, specificity)\n",
    "\"dole primjer za als - 3 modificirane funkcije i onda se samo pozove - nije bas savrseno al mislim da ce bit skroz ok za nasih par modela\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def als_get_recs(i, n, model, c_train, n_groups):\n",
    "    recs = model.recommend(i, user_items = csr_matrix(c_train), N = n, filter_already_liked_items = True, filter_items = [j for j in range(c_train.shape[0]-n_groups)])\n",
    "    indices = [rec[0]-n_users for rec in recs]\n",
    "    scores = [rec[1] for rec in recs]\n",
    "    score = np.zeros(n_groups)\n",
    "    score[indices] = scores\n",
    "    score_index = np.flip(np.argsort(score))\n",
    "    return score_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def als_model(alpha, svd_rank, s, a_train, a_val, n_users, n_groups):\n",
    "    c_train, c_val = prepare_train_data(alpha, s, a_train, a_val)\n",
    "    model = implicit.als.AlternatingLeastSquares(factors = n_factors, regularization = 2)\n",
    "    model.fit(c_train)    \n",
    "    precision, sensitivity, specificity = evaluate_model(model, c_train, c_val, n_users, n_groups, model_type = \"ALS\")\n",
    "    score = get_score(precision, sensitivity, specificity)\n",
    "    return {\"alpha\" : alpha, \"n_factors\" : n_factors, \"score\" : score, \"precision\" : precision, \"sensitivity\" : sensitivity, \"specificity\" : specificity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_als_model(alphas, n_factors, s, a_train, a_val, n_users, n_groups):\n",
    "    validation_scores = []\n",
    "    for alpha in alphas:\n",
    "        for nf in n_factors:\n",
    "            validation_scores.append(als_model(alpha, nf, s, a_train, a_val, n_users, n_groups))\n",
    "    return validation_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [3]\n",
    "n_factors = [10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_scores_als = validate_als_model(alphas, n_factors, s, a_train, a_val, n_users, n_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_scores_als"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(1 - validation_scores_als[0][\"specificity\"], validation_scores_als[0][\"sensitivity\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Katz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def katz(t, beta, k):\n",
    "    katz = beta*t\n",
    "    a = beta*t\n",
    "    for i in range(k-1):\n",
    "        a = beta*a@t\n",
    "        katz = katz + a\n",
    "    return katz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def katz_2(t, beta, k):\n",
    "    t = t.astype(np.float64)\n",
    "    u, s, vt = svds(t, k=3)\n",
    "    s = np.diag(s)\n",
    "    \n",
    "    vtu = vt@u\n",
    "    svtu = s@vtu\n",
    "    \n",
    "    katz = beta*s\n",
    "    #a = beta*svtu\n",
    "    small_matrix = beta * s @ vtu\n",
    "    for i in range(k-1):\n",
    "        small_matrix = beta * small_matrix @ s\n",
    "        katz = katz + small_matrix\n",
    "        small_matrix = small_matrix @ vtu\n",
    "    katz = u @ katz @ vt\n",
    "    return katz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
