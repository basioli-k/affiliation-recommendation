{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UPOZORENJA\n",
    "- ćelija za učitavanje podataka treba malo više vremena (get_user_data), pozvati jednom i nakon toga zakomentirati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO-ovi\n",
    "- smisliti kako ćemo odabrati bolji dio podataka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.sparse import csc_matrix, bmat, save_npz\n",
    "from scipy.sparse.linalg import svds\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "- reading user data from given files (we are considering only users that are in some group here)\n",
    "- random sample of filtered users\n",
    "- normalizing user data (renaming users to elements of $\\{0, ..., n-1\\}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_users(users):\n",
    "    usrs = list(set(users.keys()).union(set([link  for key in users for link in users[key][\"links\"] ])))\n",
    "    groups = list(set([group for key in users for group in users[key][\"groups\"] ]))\n",
    "    normalized_users = {}\n",
    "    for user in users:\n",
    "        normalized_users[usrs.index(user)] = {}\n",
    "        normalized_users[usrs.index(user)][\"links\"] = [usrs.index(link) for link in users[user][\"links\"]]\n",
    "        normalized_users[usrs.index(user)][\"groups\"] = [groups.index(group) for group in users[user][\"groups\"]]\n",
    "    return normalized_users    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_users(user_number, all_users):\n",
    "    # add any additional filters here if needed (ex. at least 2 groups and 3 links)\n",
    "    \n",
    "    # filters like this will work only if set for groups because in the next step we are \n",
    "    # filtering links that aren't in our subgraph\n",
    "    users = copy.deepcopy(all_users)\n",
    "    print(\"Number of users in full dataset : \" + str(len(users)))\n",
    "    users = {user: users[user] for user in users if len(users[user][\"links\"]) >= 2 and len(users[user][\"groups\"]) >= 2}\n",
    "    print(\"Number of users in filtered dataset : \" + str(len(users)))\n",
    "    \n",
    "    keys = random.sample(users.keys(), user_number)\n",
    "    users = {key: users[key] for key in keys}\n",
    "    \n",
    "    #first eliminate any links that remained in the graph and shouldn't be there\n",
    "    for user in users:\n",
    "        users[user][\"links\"] = list(filter(lambda link: link in users.keys(), users[user][\"links\"]))\n",
    "        \n",
    "    return normalize_users(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_data(links_path, groups_path):\n",
    "    # return a list of two dictionaries-users and groups\n",
    "    # users-return all user data where every user is in at least one group\n",
    "    links = np.loadtxt(links_path)\n",
    "    groups = np.loadtxt(groups_path)\n",
    "    users = {} # key is user, value is dict containing all of his links and all of his groups\n",
    "    groups_info = {} # key is group, value is dict containing all of its users\n",
    "    \n",
    "    for edge in groups:\n",
    "        if edge[0] not in users:\n",
    "            users[edge[0]] = { \"links\": [], \"groups\":[] }\n",
    "        users[edge[0]][\"groups\"].append(edge[1])\n",
    "        if edge[1] not in groups_info:\n",
    "            groups_info[edge[1]] = { \"users\": [] }\n",
    "        groups_info[edge[1]][\"users\"].append(edge[0])\n",
    "        \n",
    "    for link in links:\n",
    "        if link[0] not in users or link[1] not in users: continue\n",
    "        if link[1] in users[link[0]][\"links\"]: continue\n",
    "        if link[0] in users[link[1]][\"links\"]: continue\n",
    "        users[link[0]][\"links\"].append(link[1])\n",
    "        users[link[1]][\"links\"].append(link[0])\n",
    "    \n",
    "    return [users, groups_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_connections(user, groups_users_list):\n",
    "    # return a list of all user's friends and group friends\n",
    "    connections=[friend for friend in groups_users_list[0][user][\"links\"]]\n",
    "    for group in groups_users_list[0][user][\"groups\"]:\n",
    "        for friend in groups_users_list[1][group][\"users\"]:\n",
    "            connections.append(friend)\n",
    "    return list(set(connections))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree(final_network, last_added, k, groups_users_list):\n",
    "    #  second iteration: last_added = [user_connections(user) for user in last_added] - final_network \n",
    "    l=[]\n",
    "    if k==0:\n",
    "        return final_network\n",
    "    else:\n",
    "        tree_level=[]\n",
    "        for friend in last_added:\n",
    "            tree_level.extend(user_connections(friend, groups_users_list))\n",
    "        last_added=list(set(tree_level)-set(final_network))\n",
    "        final_network.extend(last_added)\n",
    "        return tree(final_network, last_added, k-1, groups_users_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adjacency_matrix(users, key, row_num, col_num):\n",
    "    # constructs adjacency matrix\n",
    "    # rows are indexed by user\n",
    "    # cols are indexed based on the key\n",
    "    row = np.array([])\n",
    "    column = np.array([])\n",
    "    value = np.array([])\n",
    "    \n",
    "    for user in users:\n",
    "        for element in users[user][key]:\n",
    "            row = np.append(row, user)\n",
    "            column = np.append(column, element)\n",
    "            value = np.append(value, 1)\n",
    "    \n",
    "    s = csc_matrix((value, (row, column)), shape = (row_num, col_num))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "# this takes some time so comment it out after first run\n",
    "%time all_users_and_groups = get_user_data(\"data/raw/release-youtube-links.txt\", \"data/raw/release-youtube-groupmemberships.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ovo mora biti nula, panika ako nije nula\n",
    "if sum(user not in all_users_and_groups[0][neigh][\"links\"] for user in all_users_and_groups[0]\n",
    "   for neigh in all_users_and_groups[0][user][\"links\"]) != 0:\n",
    "    for i in range(10): print(\"PANIC!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_network = [1.0]\n",
    "last_added = [1.0]\n",
    "max_tree_level = 2\n",
    "all_users = {user: all_users_and_groups[0][user] for user in tree(final_network, last_added, max_tree_level, all_users_and_groups)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isto kao prethodno ovo MORA biti nula, čini se da funckija tree ne odrzava graf onako kako bi trebala\n",
    "\"\"\"\n",
    "if sum(user not in all_users[neigh][\"links\"] for user in all_users\n",
    "   for neigh in all_users[user][\"links\"]) != 0:\n",
    "    for i in range(10): print(\"PANIC!\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_basic_stats(dataset, dataset_name):\n",
    "    print(dataset_name)\n",
    "    print(\"median:\", np.median(dataset), \"average:\", np.mean(dataset), \n",
    "            \"max:\", np.amax(dataset), \"minimum\", np.amin(dataset))\n",
    "\n",
    "def get_network_stats(users):\n",
    "    all_users = np.array(list(users.keys()))\n",
    "    user_link_count = np.array([len(users[user][\"links\"]) for user in all_users])\n",
    "    user_group_count = np.array([len(users[user][\"groups\"]) for user in all_users])\n",
    "\n",
    "    groups = np.unique(np.array([group for user in users for group in users[user][\"groups\"]]))\n",
    "    group_user_count = np.zeros(len(groups))\n",
    "    print(\"There are\",len(all_users), \"users and\", len(groups), \"groups.\")\n",
    "    # user count of groups[i] is located at group_user_count[i]\n",
    "    for user in users:\n",
    "        for group in users[user][\"groups\"]:\n",
    "            index, = np.where(groups == group)\n",
    "            if len(index) != 1: raise Exception(\"There are duplicates in your groups array. Check for error.\")\n",
    "            group_user_count[index[0]] += 1  # we can use group_user_count[group] here but this is more general\n",
    "\n",
    "    # sad za sve ovo neke statistike\n",
    "    fig1, axs1 = plt.subplots(1, 2, constrained_layout=True, squeeze=True)\n",
    "    axs1[0].boxplot(user_link_count)\n",
    "    axs1[0].set_title(\"User link boxplot\")\n",
    "    axs1[1].hist(user_link_count)\n",
    "    axs1[1].set_title(\"User link histogram\")\n",
    "    print_basic_stats(user_link_count, \"User link count\")\n",
    "    \n",
    "    fig2, axs2 = plt.subplots(1, 2, constrained_layout=True, squeeze=True)\n",
    "    axs2[0].boxplot(user_group_count)\n",
    "    axs2[0].set_title(\"User group boxplot\")\n",
    "    axs2[1].hist(user_group_count)\n",
    "    axs2[1].set_title(\"User group histogram\")\n",
    "    print_basic_stats(user_group_count, \"User group count\")\n",
    "\n",
    "    fig3, axs3 = plt.subplots(1, 2, constrained_layout=True, squeeze=True)\n",
    "    axs3[0].boxplot(group_user_count)\n",
    "    axs3[0].set_title(\"Group user boxplot\")\n",
    "    axs3[1].hist(group_user_count)\n",
    "    axs3[1].set_title(\"Group user histogram\")\n",
    "    print_basic_stats(group_user_count, \"Group user count\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of users\n",
    "# WARNING: small number of users will usually result in a small number of links between users\n",
    "k = 15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quickly gets a filtered subset of users\n",
    "filtered_users = filter_users(k, all_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_network_stats(filtered_users)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# S matrix, matrix of links between users\n",
    "s = get_adjacency_matrix(filtered_users, \"links\", len(filtered_users), len(filtered_users))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# A matrix, affiliation matrix, links between users and groups\n",
    "# how many groups are there?\n",
    "a = get_adjacency_matrix(filtered_users, \"groups\", len(filtered_users), len(set([group for user in filtered_users for group in filtered_users[user][\"groups\"]])))\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_train = a.toarray()\n",
    "for row in a_train:\n",
    "    ones = np.transpose(row.nonzero())\n",
    "    indices = np.random.randint(len(ones), size = round(len(ones)*0.3))\n",
    "    row[ones[indices]] = 0\n",
    "a_test = csc_matrix(a - a_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in a_train:\n",
    "    ones = np.transpose(row.nonzero())\n",
    "    indices = np.random.randint(len(ones), size = round(len(ones)*0.3))\n",
    "    row[ones[indices]] = 0\n",
    "a_val = csc_matrix(a - a_train - a_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_npz(\"data/yt_s.npz\", s)\n",
    "save_npz(\"data/yt_a.npz\", a)\n",
    "save_npz(\"data/yt_a_train.npz\", csc_matrix(a_train))\n",
    "save_npz(\"data/yt_a_val.npz\", a_val)\n",
    "save_npz(\"data/yt_a_test.npz\", a_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_matrix_to_file(matrix, output):\n",
    "    with open(output, \"w\") as output:\n",
    "        for i, row in enumerate(matrix):\n",
    "            for j, el in enumerate(row):\n",
    "                if el == 1:\n",
    "                    output.write(str(i+1) + \" \" + str(j+1) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uzasno dugo traje\n",
    "data_path = [(a_train, \"data/random_katz/yt_a_train.txt\"), (a_val.toarray(), \"data/random_katz/yt_a_val.txt\"), \n",
    "             (a_test.toarray(), \"data/random_katz/yt_a_test.txt\"), (a.toarray(), \"data/random_katz/yt_a.txt\"),\n",
    "            (s.toarray(), \"data/random_katz/yt_s.txt\")]\n",
    "\n",
    "for data, path in tqdm(data_path):\n",
    "    print_matrix_to_file(data, path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
