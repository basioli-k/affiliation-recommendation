{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UPOZORENJA\n",
    "- ćelija za učitavanje podataka treba malo više vremena (get_user_data), pozvati jednom i nakon toga zakomentirati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO-ovi\n",
    "- smisliti kako ćemo odabrati bolji dio podataka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.sparse import csc_matrix, bmat, save_npz\n",
    "from scipy.sparse.linalg import svds\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "- reading user data from given files (we are considering only users that are in some group here)\n",
    "- random sample of filtered users\n",
    "- normalizing user data (renaming users to elements of $\\{0, ..., n-1\\}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_users(users):\n",
    "    usrs = list(set(users.keys()).union(set([link  for key in users for link in users[key][\"links\"] ])))\n",
    "    groups = list(set([group for key in users for group in users[key][\"groups\"] ]))\n",
    "    normalized_users = {}\n",
    "    for user in users:\n",
    "        normalized_users[usrs.index(user)] = {}\n",
    "        normalized_users[usrs.index(user)][\"links\"] = [usrs.index(link) for link in users[user][\"links\"]]\n",
    "        normalized_users[usrs.index(user)][\"groups\"] = [groups.index(group) for group in users[user][\"groups\"]]\n",
    "    return normalized_users    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_users(user_number, all_users):\n",
    "    # add any additional filters here if needed (ex. at least 2 groups and 3 links)\n",
    "    \n",
    "    # filters like this will work only if set for groups because in the next step we are \n",
    "    # filtering links that aren't in our subgraph\n",
    "    users = copy.deepcopy(all_users)\n",
    "    print(\"Number of users in full dataset : \" + str(len(users)))\n",
    "    users = {user: users[user] for user in users if len(users[user][\"links\"]) >= 2 and len(users[user][\"groups\"]) >= 2}\n",
    "    print(\"Number of users in filtered dataset : \" + str(len(users)))\n",
    "    \n",
    "    #keys = random.sample(users.keys(), user_number)\n",
    "    #users = {key: users[key] for key in keys}\n",
    "    \n",
    "    #first eliminate any links that remained in the graph and shouldn't be there\n",
    "    for user in users:\n",
    "        users[user][\"links\"] = list(filter(lambda link: link in users.keys(), users[user][\"links\"]))\n",
    "        \n",
    "    return normalize_users(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_data(links_path, groups_path):\n",
    "    # return a list of two dictionaries-users and groups\n",
    "    # users-return all user data where every user is in at least one group\n",
    "    links = np.loadtxt(links_path)\n",
    "    groups = np.loadtxt(groups_path)\n",
    "    users = {} # key is user, value is dict containing all of his links and all of his groups\n",
    "    groups_info = {} # key is group, value is dict containing all of its users\n",
    "    \n",
    "    for edge in groups:\n",
    "        if edge[0] not in users:\n",
    "            users[edge[0]] = { \"links\": [], \"groups\":[] }\n",
    "        users[edge[0]][\"groups\"].append(edge[1])\n",
    "        if edge[1] not in groups_info:\n",
    "            groups_info[edge[1]] = { \"users\": [] }\n",
    "        groups_info[edge[1]][\"users\"].append(edge[0])\n",
    "        \n",
    "    for link in links:\n",
    "        if (link[0] in users) and (link[1] in users):\n",
    "            users[link[0]][\"links\"].append(link[1])\n",
    "    \n",
    "    return [users, groups_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_connections(user, groups_users_list):\n",
    "    # return a list of all user's friends and group friends\n",
    "    connections=[friend for friend in groups_users_list[0][user][\"links\"]]\n",
    "    for group in groups_users_list[0][user][\"groups\"]:\n",
    "        for friend in groups_users_list[1][group][\"users\"]:\n",
    "            connections.append(friend)\n",
    "    return list(set(connections))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(final_network, groups_users_list):\n",
    "    users = {user:groups_users_list[0][user] for user in final_network}\n",
    "    return users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree(final_network, last_added, k, groups_users_list):\n",
    "    #  second iteration: last_added = [user_connections(user) for user in last_added] - final_network \n",
    "    l=[]\n",
    "    if k==0:\n",
    "        return final_network\n",
    "    else:\n",
    "        tree_level=[]\n",
    "        for friend in last_added:\n",
    "            tree_level.extend(user_connections(friend, groups_users_list))\n",
    "        last_added=list(set(tree_level)-set(final_network))\n",
    "        final_network.extend(last_added)\n",
    "        print(final_network)\n",
    "        return tree(final_network, last_added, k-1, groups_users_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adjacency_matrix(users, key, row_num, col_num):\n",
    "    # constructs adjacency matrix\n",
    "    # rows are indexed by user\n",
    "    # cols are indexed based on the key\n",
    "    row = np.array([])\n",
    "    column = np.array([])\n",
    "    value = np.array([])\n",
    "    \n",
    "    for user in users:\n",
    "        for element in users[user][key]:\n",
    "            row = np.append(row, user)\n",
    "            column = np.append(column, element)\n",
    "            value = np.append(value, 1)\n",
    "    \n",
    "    s = csc_matrix((value, (row, column)), shape = (row_num, col_num))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 33.1 s\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "# this takes some time so comment it out after first run\n",
    "%time all_users_and_groups = get_user_data(\"release-youtube-links.txt\", \"release-youtube-groupmemberships.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_network = [1.0]\n",
    "last_added = [1.0]\n",
    "max_tree_level = 3 \n",
    "all_users = filter_data(tree(final_network, last_added, max_tree_level, all_users_and_groups),all_users_and_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of users\n",
    "# WARNING: small number of users will usually result in a small number of links between users\n",
    "k = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users in full dataset : 94238\n",
      "Number of users in filtered dataset : 26968\n"
     ]
    }
   ],
   "source": [
    "# quickly gets a filtered subset of users\n",
    "filtered_users = filter_users(k, all_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<26968x26968 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 389470 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# S matrix, matrix of links between users\n",
    "s = get_adjacency_matrix(filtered_users, \"links\", len(filtered_users), len(filtered_users))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x4922 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 10020 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A matrix, affiliation matrix, links between users and groups\n",
    "# how many groups are there?\n",
    "a = get_adjacency_matrix(filtered_users, \"groups\", len(filtered_users), len(set([group for user in filtered_users for group in filtered_users[user][\"groups\"]])))\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_train = a.toarray()\n",
    "for row in a_train:\n",
    "    ones = np.transpose(row.nonzero())\n",
    "    indices = np.random.randint(len(ones), size = round(len(ones)*0.3))\n",
    "    row[ones[indices]] = 0\n",
    "a_test = csc_matrix(a - a_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in a_train:\n",
    "    ones = np.transpose(row.nonzero())\n",
    "    indices = np.random.randint(len(ones), size = round(len(ones)*0.3))\n",
    "    row[ones[indices]] = 0\n",
    "a_val = csc_matrix(a - a_train - a_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_npz(\"data/s.npz\", s)\n",
    "save_npz(\"data/a.npz\", a)\n",
    "save_npz(\"data/a_train.npz\", csc_matrix(a_train))\n",
    "save_npz(\"data/a_val.npz\", a_val)\n",
    "save_npz(\"data/a_test.npz\", a_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
